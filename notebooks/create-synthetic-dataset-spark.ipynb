{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some synthetic data - using the `dbldatagen` package in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs:\n",
    "- https://databrickslabs.github.io/dbldatagen/public_docs/index.html\n",
    "- https://pyparsing-docs.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Needed to first install Java for using Spark\n",
    "\n",
    "https://www.oracle.com/java/technologies/downloads/#jdk20-mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import dbldatagen as dg\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = (\n",
    "#     SparkSession.builder\n",
    "#     .appName(\"tmp\")\n",
    "#     .getOrCreate() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark_jars = (\n",
    "    \"org.apache.spark:spark-avro_2.13:3.4.1\"\n",
    "    \",io.delta:delta-core_2.13:2.4.0\"\n",
    "    \",com.databricks:spark-xml_2.13:0.16.0\"\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"MyApp\")\n",
    "    .config(\"spark.jars.packages\", spark_jars)\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )    \n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "    .config(\"spark.ui.enabled\", \"false\")\n",
    "    .config(\"spark.ui.dagGraph.retainedRootRDDs\", \"1\")\n",
    "    .config(\"spark.ui.retainedJobs\", \"1\")\n",
    "    .config(\"spark.ui.retainedStages\", \"1\")\n",
    "    .config(\"spark.ui.retainedTasks\", \"1\")\n",
    "    .config(\"spark.sql.ui.retainedExecutions\", \"1\")\n",
    "    .config(\"spark.worker.ui.retainedExecutors\", \"1\")\n",
    "    .config(\"spark.worker.ui.retainedDrivers\", \"1\")\n",
    "    .config(\"spark.driver.memory\", \"16g\") \n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = 10 * 1000 * 1000\n",
    "\n",
    "test_data_spec = (\n",
    "    dg.DataGenerator( spark, name=\"test_data_set1\", rows=row_count, partitions=4, \n",
    "                      randomSeedMethod=\"hash_fieldname\", verbose=True, )\n",
    "    .withColumn(\"purchase_id\", IntegerType(), minValue=1000000, maxValue=2000000)\n",
    "    .withColumn(\"product_code\", IntegerType(), uniqueValues=10000, random=True)\n",
    "    .withColumn(\n",
    "        \"purchase_date\",\n",
    "        \"date\",\n",
    "        data_range=dg.DateRange(\"2017-10-01 00:00:00\", \"2018-10-06 11:55:00\", \"days=3\"),\n",
    "        random=True,\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"return_date\",\n",
    "        \"date\",\n",
    "        expr=\"date_add(purchase_date, cast(floor(rand() * 100 + 1) as int))\",\n",
    "        baseColumn=\"purchase_date\",\n",
    "    )\n",
    "    .withColumn(\"name\", \"string\", percentNulls=0.01, template=r'\\\\\\\\w \\\\\\\\w|\\\\\\\\w A. \\\\\\\\w|test')\n",
    "    .withColumn(\"emails\", \"string\", template=r'\\\\\\\\w.\\\\\\\\w@\\\\\\\\w.com', random=True,\n",
    "                 numFeatures=(1, 6), structType=\"array\")\n",
    ")\n",
    "df_test_data = test_data_spec.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data.count() / 1000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data.limit(5).show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"../data/delta/sample_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
